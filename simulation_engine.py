import argparse
import numpy as np
import pandas as pd
from numba import njit, prange

# -----------------------------------------
# Efficient batch-based Gaussian sampling
# -----------------------------------------
@njit(fastmath=True, nogil=True)
def generate_normal_batch(n, p, seed):
    """Generates a batch of standard normal random variables."""
    rng = np.random.RandomState(seed)
    return rng.normal(0.0, 1.0, (n, p))

# -----------------------------------------
# Fast MEWMA simulation kernel
# -----------------------------------------
@njit(fastmath=True, nogil=True, parallel=True)
def simulate_batch(lamb, h, L, inv_mat, shift, scale, seeds, max_steps):
    """Performs the MEWMA simulation for a batch of seeds."""
    n = seeds.shape[0]
    p = shift.shape[0]
    results = np.empty(n, dtype=np.int32)

    for i in prange(n):
        rng = np.random.RandomState(seeds[i])
        Z = np.zeros(p)
        for t in range(1, max_steps + 1):
            noise = rng.normal(0.0, 1.0, p)
            # L.dot(noise) - Ø§ÛŒÙ†Ø¬Ø§ L Ù…Ø§ØªØ±ÛŒØ³ Ù…Ø«Ù„Ø«ÛŒ Ù¾Ø§ÛŒÛŒÙ† Ø§Ø³Øª (Cholesky decomposition)
            X = shift + scale * L.dot(noise)
            Z = (1 - lamb) * Z + lamb * X
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¢Ù…Ø§Ø±Ù‡ T-squared: Z^T * inv_mat * Z
            stat = Z @ inv_mat @ Z
            
            if stat > h:
                results[i] = t
                break
        else:
            results[i] = max_steps
    return results

# -----------------------------------------
# Main
# -----------------------------------------
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--lambda_value", type=float, required=True)
    parser.add_argument("--n_sim", type=int, default=50000)
    parser.add_argument("--base_seed", type=int, default=1234)
    parser.add_argument("--out", type=str, default="results")
    args = parser.parse_args()

    lamb = args.lambda_value

    ## ğŸ› ï¸ Ø±ÙØ¹ Ø®Ø·Ø§: Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø¹Ø¯Ø¯ÛŒ Ø¨ÙˆØ¯Ù† L Ùˆ Ø³Ø§Ø®ØªØ§Ø± ØµØ­ÛŒØ­ Ø¨Ø±Ø§ÛŒ np.cov
    
    # 1. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø§ØªØ±ÛŒØ³ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ÙØ§Ø² 2
    # ÙØ±Ø¶ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… ÙØ§ÛŒÙ„ 'phase2_final_features.csv' Ø¯Ø§Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Sample x Feature Ø§Ø³Øª.
    # Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®ÙˆØ§Ù†Ø¯Ù† Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒ (Ù…Ø«Ù„ Ø§ÛŒÙ†Ø¯Ú©Ø³ ÛŒØ§ Ù‡Ø¯Ø±)ØŒ Ø§Ø² Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø²ÛŒØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…:
    df = pd.read_csv(
        "phase2_final_features.csv",
        header=None, # ÙØ±Ø¶ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… ÙØ§ÛŒÙ„ ÙØ§Ù‚Ø¯ Ø±Ø¯ÛŒÙ Ù‡Ø¯Ø± Ù…ØªÙ†ÛŒ Ø§Ø³Øª
        skiprows=1 if pd.read_csv("phase2_final_features.csv").iloc[0].dtype == object else 0 # Ø§Ú¯Ø± Ø±Ø¯ÛŒÙ Ø§ÙˆÙ„ Ø±Ø´ØªÙ‡ Ø¨ÙˆØ¯ØŒ Ø¢Ù† Ø±Ø§ Ø­Ø°Ù Ú©Ù†
    )
    
    # L_raw Ø´Ø§Ù…Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ù‡Ù…Ø±Ø§Ù‡ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ ØºÛŒØ± ÙˆÛŒÚ˜Ú¯ÛŒ (Ù…Ø«Ù„ ID ÛŒØ§ Ø§ÛŒÙ†Ø¯Ú©Ø³) Ø§Ø³Øª.
    # Ø³ØªÙˆÙ† Ø§ÙˆÙ„ (Index 0) Ø±Ø§ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø³ØªÙˆÙ† ØºÛŒØ± ÙˆÛŒÚ˜Ú¯ÛŒ Ø­Ø°Ù Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ùˆ Ø¨Ø§Ù‚ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ø±Ø§ Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ….
    L_features = df.iloc[:, 1:].values 
    
    # 2. ØªØ¨Ø¯ÛŒÙ„ Ø§Ø¬Ø¨Ø§Ø±ÛŒ Ø¨Ù‡ Ù†ÙˆØ¹ float Ø¨Ø±Ø§ÛŒ Ø±ÙØ¹ TypeError
    # Ø§ÛŒÙ† Ú¯Ø§Ù… Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ú©Ù‡ Ù‡ÛŒÚ† Ø±Ø´ØªÙ‡â€ŒØ§ÛŒ Ø¯Ø± Ø¢Ø±Ø§ÛŒÙ‡ Ø¨Ø§Ù‚ÛŒ Ù†Ù…Ø§Ù†Ø¯Ù‡ Ø§Ø³Øª.
    try:
        L_numeric = L_features.astype(np.float64)
    except ValueError as e:
        print(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ¨Ø¯ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¹Ø¯Ø¯. Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯ Ú©Ù‡ 'phase2_final_features.csv' ÙÙ‚Ø· Ø´Ø§Ù…Ù„ Ø§Ø¹Ø¯Ø§Ø¯ Ø§Ø³Øª: {e}")
        return
        
    # 3. Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ np.cov
    # np.cov Ø§Ù†ØªØ¸Ø§Ø± Ø¯Ø§Ø±Ø¯ Features Ø¯Ø± Ø³Ø·Ø±Ù‡Ø§ Ùˆ Samples Ø¯Ø± Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ø¨Ø§Ø´Ù†Ø¯.
    # Ø§Ú¯Ø± L_numeric Ø¨Ù‡ ØµÙˆØ±Øª (Samples x Features) Ø§Ø³ØªØŒ Ø¨Ø§ÛŒØ¯ ØªØ±Ø§Ù†Ù‡Ø§Ø¯Ù‡ Ø´ÙˆØ¯.
    L = L_numeric.T 
    
    p = L.shape[0] # p: ØªØ¹Ø¯Ø§Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§

    # 4. Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø§ØªØ±ÛŒØ³ Ú©ÙˆÙˆØ§Ø±ÛŒØ§Ù†Ø³ Ùˆ Ù…Ø¹Ú©ÙˆØ³ Ø¢Ù† (Ø­Ø§Ù„Ø§ Ø¨Ø¯ÙˆÙ† TypeError)
    inv_mat = np.linalg.inv(np.cov(L))
    
    # ----------------------------------------------------
    
    # Example shift vectors (IC, small, moderate ...)
    scenarios = {
        "IC":       np.zeros(p),
        "small":    np.ones(p) * 0.1,
        "moderate": np.ones(p) * 0.3,
        "large":    np.ones(p) * 0.6,
    }

    # Calibrated h (placeholder: set per-lambda)
    # ğŸ’¡ ØªÙˆØ¬Ù‡: Ù…Ù‚Ø¯Ø§Ø± h Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø¨Ø§ÛŒØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ ARL0 Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø¯Ø± Ø­Ø§Ù„Øª IC Ú©Ø§Ù„ÛŒØ¨Ø±Ù‡ Ø´ÙˆØ¯.
    h = 8.5 

    # ØªÙˆÙ„ÛŒØ¯ Ø¨Ø°Ø±Ù‡Ø§ (seeds) Ø¨Ø±Ø§ÛŒ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ§Ø²ÛŒ
    rng_main = np.random.RandomState(args.base_seed)
    seeds = rng_main.randint(0, 2**32, size=args.n_sim)

    records = []
    for name, shift in scenarios.items():
        res = simulate_batch(
            lamb, h, L, inv_mat, shift,
            scale=1.0,
            seeds=seeds,
            max_steps=50000
        )
        arl = res.mean()
        records.append([lamb, name, arl])

    # 5. Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬
    out_df = pd.DataFrame(records, columns=["Lambda", "Scenario", "ARL"])
    out_df.to_csv(f"{args.out}/results_lambda_{lamb}.csv", index=False)

if __name__ == "__main__":
    main()
